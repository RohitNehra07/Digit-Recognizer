{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Lambda, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPool2D, AvgPool2D\n",
    "\n",
    "# optimizer, data generator and learning rate reductor\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):                   #on_epoch_end is called when an epoch ends, if the name of function is changed then it won't work\n",
    "        print(\"log: \" + str(logs))\n",
    "        if(logs.get('loss')<0.0001):\n",
    "            #print(\"\\nReached 80% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"/Users/vaibhav/Downloads/train.csv\")\n",
    "trainy = train['label']\n",
    "trainx = train.drop(\"label\", axis=1)\n",
    "\n",
    "testx = pd.read_csv(\"/Users/vaibhav/Downloads/test.csv\")\n",
    "    \n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size = 3, activation='relu', input_shape = (28,28,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size = 3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size = 3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size = 4, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=tf.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate__model(model, trainX, trainY, testX):\n",
    "    model.fit(trainX, trainY,epochs=20, callbacks = [callbacks], batch_size=64)\n",
    "    #print(model.evaluate(x=testX, y=testY))\n",
    "    predictions = model.predict(testX)\n",
    "    \n",
    "\n",
    "trainx = trainx.values.reshape(42000,28,28,1)           #for convolution layer(it expects everything in single tensor[4-d] and not 60000 images as a list in dense layer)\n",
    "testx = testx.values.reshape(28000,28,28,1)             #for convolution layer\n",
    "\n",
    "\n",
    "#one hot encoder label\n",
    "trainy = to_categorical(trainy, num_classes = 10)\n",
    "\n",
    "#trainX, testX, trainY, testY = train_test_split(trainx, trainy, test_size = 0.1)\n",
    "\n",
    "#normalisation\n",
    "trainx = np.array(trainx)/255.0\n",
    "testx = np.array(testx)/255.0\n",
    "model = None\n",
    "model = create_model()\n",
    "train_and_evaluate__model(model, trainx, trainy, testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageId = []\n",
    "for i in range(1, 28001):\n",
    "    ImageId.append(i)\n",
    "df = pd.DataFrame(columns = {\"ImageId\"}, data = ImageId)\n",
    "df[\"Label\"] = predictions\n",
    "df.to_csv(\"----add location to store the csv file----\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
